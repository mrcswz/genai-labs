{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Text Prompt Design: Challenge Lab\n",
    "\n",
    "## Overview\n",
    "\n",
    "This challenge lab is designed to test your knowledge of calling Gemini and utilizing a few fundamental text prompt design techniques.\n",
    "\n",
    "Two featured guides on prompting from the Google Cloud documentation are:\n",
    "\n",
    "1. [Overview of prompting strategies](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-design-strategies) from the Generative AI on Vertex AI documentation.\n",
    "\n",
    "2. [Prompt design strategies](https://ai.google.dev/gemini-api/docs/prompting-strategies) from the Gemini API documentation.\n",
    "\n",
    "Both contain good tips. You are encouraged to **bookmark them**.\n",
    "\n",
    "## Objective\n",
    "You will demonstrate your ability to:\n",
    "\n",
    "- Initialize Vertex AI in your environment\n",
    "- Load a generative model\n",
    "- Guide model output with a persona\n",
    "- Extract information to a schema\n",
    "- Stay on topic with fallback responses\n",
    "- Use examples to influence the model's response\n",
    "\n",
    "Some of the following Python notebook cells have missing or incomplete code sections and tasks that need to be completed, indicated by the code comments starting with `# TODO`. Your challenge is to complete each cell, run it to test for correctness, and then move on. When all the cells are working, you have completed the challenge.\n",
    "\n",
    "**Note:** If you need help, [this notebook demonstrates getting started using Gemini in Python](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5afkyDMSBW5"
   },
   "source": [
    "## Task 1. Install, import & initialize the Vertex AI SDK and a generative model\n",
    "\n",
    "1. Install the Vertex AI SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kc4WxYmLSBW5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform==1.55.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQwwRiniVFG"
   },
   "source": [
    "2. Restart your notebook kernel.\n",
    "3. Import the following:\n",
    "- the Vertex AI SDK\n",
    "- the class to instantiate a generative model from the Vertex AI generative models module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kpdnPWaTK27C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Fom0ZkMSBW6"
   },
   "source": [
    "4. Initialize Vertex AI with your project ID and a location (you can use `us-central1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LCaCx6PLSBW6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project='qwiklabs-gcp-02-ce3f30b33be4', location='us-central1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8DUcgKJK27C"
   },
   "source": [
    "5. Instantiate a generative model and save it to the `generative_model` variable. For this notebook, use `gemini-pro` as your model version. When instantiating the model, pass a `generation_config` parameter with the temperature set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2998506fe6d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "generative_model = GenerativeModel(\n",
    "    \"gemini-pro\",\n",
    "    generation_config=generation_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3YN2rf1K27C"
   },
   "source": [
    "6. Complete the TODO's in this function, which you will use for the rest of the lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "joXl2V2JK27D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_response(prompt):\n",
    "\n",
    "    response = generative_model.generate_content(\n",
    "        [prompt],\n",
    "        stream=False,\n",
    "    )\n",
    "    \n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEAJ0ipmbndQ"
   },
   "source": [
    "## Task 2. Personas\n",
    "\n",
    "1. Run the following cell to see the default response to this prompt.\n",
    "\n",
    "2. Then tweak the prompt by asking the model to take on the persona of an **energetic, inspiring personal trainer** who can get users **excited to work out their leg muscles**. Note the difference in vocabulary and tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEo0QhauK27D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Context: You are an energetic, inspiring personal trainer who can get users excited to work out their leg muscles on an active routine.\"\n",
    "Prompt: What are some good leg exercises?\n",
    "\"\"\"\n",
    "\n",
    "print_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueKZMheeK27D"
   },
   "source": [
    "## Task 3. Be specific + constrain the output format\n",
    "\n",
    "1. Have the model convert the following text of cooking ingredients to a YAML format. Each ingredient should be listed as a dictionary with keys for **ingredient** and **quantity** populated with the correct value given the ingredients in the following recipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qyJASDrsK27D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = \"Show me those ingredients in a YAML format, where each ingredient is listed as a dictionary with keys for ingredient and quantity populated with the correct value given.\"\n",
    "\n",
    "ingredients = \"\"\"\n",
    "    Ingredients:\n",
    "    * 9 egg whites\n",
    "    * 3/8 tsp Cream of Tartar\n",
    "    * 1 1/2 tbs Vinegar\n",
    "    * 1 1/2 tsp Vanilla\n",
    "    * 3 cups Sugar\n",
    "    * 1 quarts Heavy whipping cream\n",
    "    * 3 boxes Strawberries\n",
    "    \"\"\"\n",
    "\n",
    "prompt = instructions + \"\\n\\n\" + ingredients\n",
    "\n",
    "print_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xRk8HTLK27D"
   },
   "source": [
    "## Task 4. Use a fallback response\n",
    "\n",
    "1. Adjust the prompt below to specify that the model should only answer questions related to historical landmarks. If a user askes about something else, the model should respond with the message: `Sorry, I only answer questions about historical landmarks!`\n",
    "\n",
    "2. Adjust your instructions until the model declines to answer the `user_query` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6InaQ3OpK27D",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, I only answer questions about historical landmarks!\n"
     ]
    }
   ],
   "source": [
    "instructions = \"You are a history tour guide. Answer the user's question: {user_query}. If the users question is not about historical landmarks, answer with: Sorry, I only answer questions about historical landmarks!\"\n",
    "\n",
    "user_query = \"How can I attract butterflies to my garden?\"\n",
    "\n",
    "print_response(instructions.format(user_query=user_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFolKJjNK27D"
   },
   "source": [
    "## Task 5. Make results more specific with examples\n",
    "\n",
    "1. Run the code cell below to see the model's response as-is.\n",
    "\n",
    "2. Imagining you work for a bicycle tour company, modify each of the example outputs below to include a bicycle.\n",
    "\n",
    "3. Re-run the code cell to make sure the model generates a bicycle-themed response. Leave the instructions alone and tweak your examples until you get such a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsjp39ZWK27D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    <INSTRUCTIONS>\n",
    "    Give a tourist recommendation for the input city.\n",
    "    </INSTRUCTIONS>\n",
    "\n",
    "    <EXAMPLES>\n",
    "    Input: Paris\n",
    "    Output: Rent a bike at the central station and the cycle to the Louvre and then to Montmartre.\n",
    "\n",
    "    Input: Washington D.C.\n",
    "    Output: Drive your rental bike to the Lincoln Memorial.\n",
    "\n",
    "    Input: New York City\n",
    "    Output: Have a great bike ride along the river.\n",
    "    </EXAMPLES>\n",
    "\n",
    "    <INPUT CITY>\n",
    "    Bangalore\n",
    "    </INPUT CITY>\"\"\"\n",
    "\n",
    "print_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvbIXnwqK27D"
   },
   "source": [
    "## Congratulations!\n",
    "\n",
    "If you have completed the steps above, you have demonstrated your ability to use several prompt engineering techniques."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_prompt_design_challenge_lab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
